<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8 Object Detection</title>
    <style>
        #webcam-container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: 20px;
        }
        #webcam {
            border: 2px solid black;
        }
    </style>
</head>
<body>
    <h1>YOLOv8 Object Detection</h1>
    <div id="webcam-container">
        <video id="webcam" width="640" height="480" autoplay></video>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/onnxruntime-web.min.js"></script>
    <script>
        // ONNX model path
        const modelPath = 'yolov8_model.onnx'; // Make sure this path is correct

        // Global variables for sound and state
        let alertSound = new Audio('alert_sound.mp3'); // Replace with actual sound file path
        let isPlaying = false;

        // Initialize webcam
        const video = document.getElementById('webcam');
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');

        // Access webcam
        navigator.mediaDevices.getUserMedia({ video: true })
            .then((stream) => {
                video.srcObject = stream;
                video.play();
            })
            .catch((error) => {
                console.error('Error accessing webcam:', error);
            });

        // Load ONNX model
        let session;

        async function loadModel() {
            try {
                session = await ort.InferenceSession.create(modelPath);
                console.log("Model loaded successfully");
                startDetection();
            } catch (err) {
                console.error("Error loading model:", err);
            }
        }

        loadModel();

        // Start object detection
        async function startDetection() {
            canvas.width = video.width;
            canvas.height = video.height;

            function detectObjects() {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                let frame = canvas.toDataURL('image/jpeg');

                // Convert image data to tensor
                let tensor = preprocessImage(frame);

                // Run inference
                session.run([tensor]).then((output) => {
                    const boxes = output[0].data;  // Adjust according to output format
                    const confidences = output[1].data;  // Adjust according to output format

                    // Check if cigarette is detected
                    let cigaretteDetected = false;

                    // Loop through detections and draw boxes
                    boxes.forEach((box, index) => {
                        const confidence = confidences[index];
                        if (confidence > 0.5) {  // Adjust the confidence threshold
                            const [x, y, width, height] = box;
                            if (/* check if the class is cigarette */) {
                                cigaretteDetected = true;
                                drawBoundingBox(x, y, width, height);
                            }
                        }
                    });

                    // Play alert sound if cigarette is detected
                    if (cigaretteDetected && !isPlaying) {
                        alertSound.play();
                        isPlaying = true;
                    } else if (!cigaretteDetected && isPlaying) {
                        alertSound.pause();
                        isPlaying = false;
                    }

                    requestAnimationFrame(detectObjects);
                }).catch((error) => {
                    console.error("Error during inference:", error);
                });
            }

            detectObjects();
        }

        // Preprocess webcam frame and convert to tensor
        function preprocessImage(frame) {
            // Convert frame to tensor here (resize, normalize, etc.)
            // This depends on the expected input format for your model
            // Example: You might need to resize the frame, normalize, etc.
            let tensor = new ort.Tensor('float32', new Float32Array(frame), [1, 3, 640, 640]);  // Adjust the shape as per model requirement
            return tensor;
        }

        // Draw bounding box on canvas
        function drawBoundingBox(x, y, width, height) {
            ctx.beginPath();
            ctx.rect(x, y, width, height);
            ctx.lineWidth = 3;
            ctx.strokeStyle = 'red';
            ctx.fillStyle = 'red';
            ctx.stroke();
        }
    </script>
</body>
</html>
